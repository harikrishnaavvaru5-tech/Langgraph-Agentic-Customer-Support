# Langgraph Agentic Customer Support

## ğŸ“ Project Overview

This project implements an **intelligent customer support agent** using **LangGraph** and **Agentic AI** principles.  
It leverages **LangChain**, **Python**, and **OpenAI** models to provide automated, context-aware customer support.

**Key Features:**

- Multi-agent orchestration for handling queries
- Integration with OpenAI GPT models
- Modular architecture for easy extension
- Virtual environment setup for isolated dependency management

---

## ğŸ’» Project Structure

Langgraph-Agentic-Customer-Support/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ orchestrator.py # Entry point for running the agent
â”‚ â”œâ”€â”€ agents/ # Individual agent modules
â”‚ â””â”€â”€ tools/ # Helper modules and utilities
â”‚
â”œâ”€â”€ venv/ # Python virtual environment (ignored in Git)
â”œâ”€â”€ requirements.txt # Project dependencies
â””â”€â”€ README.md # Project documentation

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/YOUR_USERNAME/Langgraph-Agentic-Customer-Support.git
```

cd Langgraph-Agentic-Customer-Support

2ï¸âƒ£ Create and activate virtual environment

```bash
python -m venv venv
source venv/Scripts/activate   # For Git Bash
```

3ï¸âƒ£ Install dependencies

# Initialize uv project

```bash
uv init --python 3.11
```

```bash
uv pip install langgraph langchain langchain-openai python-dotenv
```

4ï¸âƒ£ Add your API keys
Create a .env file in the root directory:

```ini
OPENAI_API_KEY=your_openai_api_key_here
```

â–¶ï¸ Running the Project
Run the orchestrator module:

```bash
python -m src.orchestrator
```
